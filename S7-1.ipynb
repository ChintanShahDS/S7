{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n09vaEgP6pLj"
   },
   "source": [
    "CODE BLOCK: 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Df6R_VinBXGE"
   },
   "source": [
    "<!--\n",
    ">**This is Bold**\n",
    ">>*This is Italics*\n",
    ">>>- Simple statement\n",
    ">>> - `string`\n",
    ">>>> - $ mathematical symbols $\n",
    ">>>> 1. Number 1\n",
    ">>>> 2. Number 2\n",
    "\n",
    "\n",
    "&#x25BA;\n",
    "\n",
    "\n",
    "*** -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DwPH_oyhBXGF"
   },
   "source": [
    "# Session 5 - Assignment - Modular and Better Commented Code\n",
    "\n",
    "# First CNN Network for MNIST\n",
    "\n",
    "## Modular Code\n",
    "- Divide the code into 3 main files\n",
    "    - model.py: *This file holds the model related details*\n",
    "    - utils.py: *This file holds the utility functions that might be commonly required*\n",
    "    - S5.ipynb: *Main Notebook file that has the variables, configuration parameters and actual calls\n",
    "    \n",
    "<a id=\"section-1\">section-1</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7dsrOigmBXGG"
   },
   "source": [
    "### [1. Import appropriate modules required in this file](#section-1)\n",
    "- import model: importing the code written in model.py that is kept in path of current working directory\n",
    "- import utils: Similarly importing code in utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6PlbomWY3RSq"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchsummary import summary\n",
    "\n",
    "import model\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VjBHHQVA6sXt"
   },
   "source": [
    "CODE BLOCK: 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dw9WOPNVBXGK"
   },
   "source": [
    "### [2. Check if GPU (CUDA) or CPU](#section-2)\n",
    "- Cuda availablbility check to ensure using GPU if available for the network\n",
    "- Taking the value into device variable if cuda (GPU) or only CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "94BxVVBP3WwS",
    "outputId": "9bfe6744-8691-4997-c7c3-fa454c9bfc5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available? True\n"
     ]
    }
   ],
   "source": [
    "SEED = 40\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"CUDA Available?\", use_cuda)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "if device==\"cuda\":\n",
    "    torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3UHq59Sw6tmW"
   },
   "source": [
    "CODE BLOCK: 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q83m4W4eLfBd"
   },
   "source": [
    "### [3. Data transforms for training and testing](#section-3)\n",
    "- Transforms specific to the training and testing\n",
    "- Training to include different transformations for the model to learn\n",
    "- Testing not to have the same to ensure validation is on normal set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "OVfqiUyyLfBe"
   },
   "outputs": [],
   "source": [
    "# Train data transformations\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    ])\n",
    "\n",
    "# Test data transformations\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gK3NQ6U6BXGM"
   },
   "source": [
    "### [4. Getting the MNIST train and test dataset from torchvision datasets library](#section-4)\n",
    "- Already separated datasets for train and test\n",
    "- train with *??* records and test with *10000* records\n",
    "- Marking train as True of False decides the train vs test data sets\n",
    "- The transforms are being loaded from utils file\n",
    "- transforms being done on train but not on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "JB79ZYW13-AO"
   },
   "outputs": [],
   "source": [
    "train = datasets.MNIST('../data', train=True, download=True, transform=train_transforms)\n",
    "test = datasets.MNIST('../data', train=False, download=True, transform=test_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_PKSHxto6116"
   },
   "source": [
    "CODE BLOCK: 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gjMoEkUJBXGY"
   },
   "source": [
    "### [5. Data loader setup for Training and Testing](#section-5)\n",
    "- Batch size definition - Keeping separate for Training and Testing\n",
    "- Training lower for better training and Testing higher for faster validation\n",
    "- Data loader definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "avCKK1uL4A68"
   },
   "outputs": [],
   "source": [
    "train_batch_size = 512\n",
    "test_batch_size = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "uqXVzK3VBXGZ"
   },
   "outputs": [],
   "source": [
    "# train_args = {'batch_size': train_batch_size, 'shuffle': True, 'num_workers': 2, 'pin_memory': True}\n",
    "# test_args = {'batch_size': test_batch_size, 'shuffle': True, 'num_workers': 2, 'pin_memory': True}\n",
    "kwargs = {'shuffle': True, 'num_workers': 2, 'pin_memory': True}\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=train_batch_size, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=test_batch_size, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install freetype=2.10.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hi_0rfq56-29"
   },
   "source": [
    "CODE BLOCK: 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cnrOq8wMBXGa"
   },
   "source": [
    "### [6. Data Visualization](#section-6)\n",
    "- Visualization of data to understand the images and corresponding labels\n",
    "- Also gives an understanding of the dataloader like Shuffle, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463
    },
    "id": "Hx7QkLcw4Epc",
    "outputId": "3b1b40ea-0cc0-4986-e505-a6d3939207cb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Trial\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\datasets\\mnist.py:75: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]\n",
      " - Numpy Shape: (60000, 28, 28)\n",
      " - Tensor Shape: torch.Size([60000, 28, 28])\n",
      " - min: tensor(-0.4242)\n",
      " - max: tensor(2.8215)\n",
      " - mean: tensor(-0.0001)\n",
      " - std: tensor(1.0000)\n",
      " - var: tensor(1.0001)\n",
      "torch.Size([512, 1, 28, 28])\n",
      "torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "# We'd need to convert it into Numpy! Remember above we have converted it into tensors already\n",
    "train_data = train.train_data\n",
    "train_data = train.transform(train_data.numpy())\n",
    "\n",
    "print('[Train]')\n",
    "print(' - Numpy Shape:', train.train_data.cpu().numpy().shape)\n",
    "print(' - Tensor Shape:', train.train_data.size())\n",
    "print(' - min:', torch.min(train_data))\n",
    "print(' - max:', torch.max(train_data))\n",
    "print(' - mean:', torch.mean(train_data))\n",
    "print(' - std:', torch.std(train_data))\n",
    "print(' - var:', torch.var(train_data))\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "# Let's visualize some of the images\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "batch_data, batch_label = next(iter(train_loader))\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "num_of_images = 60\n",
    "for index in range(1, num_of_images + 1):\n",
    "    plt.subplot(6, 10, index)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(images[index].numpy().squeeze(), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09GYKBGRAT5M"
   },
   "source": [
    "CODE BLOCK: 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NLVQ9d8PBXGb"
   },
   "source": [
    "### [7. Model training](#section-7)\n",
    "- Loading the model on the right device - CUDA or CPU\n",
    "- Setting up the right parameters like epochs, optimizer and scheduler for the training\n",
    "- Running the training and validating the output against Test dataset\n",
    "- While doing that also storing the loss and accuracy results for each epoch for understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "7du4zM474LvT"
   },
   "outputs": [],
   "source": [
    "# Data to plot accuracy and loss graphs\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_accs = []\n",
    "test_accs = []\n",
    "\n",
    "test_incorrect_pred = {'images': [], 'ground_truths': [], 'predicted_vals': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Owqiet9M4TV7",
    "outputId": "83f6ef08-ac03-4e04-adc3-4dadf00f84b6"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Calculated padded input size per channel: (2 x 2). Kernel size: (3 x 3). Kernel size can't be greater than actual input size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m mymodel \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mNet()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m----> 3\u001b[0m summary(mymodel, input_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m))\n\u001b[0;32m      5\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mSGD(mymodel\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1, verbose=True)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# New Line\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchsummary\\torchsummary.py:72\u001b[0m, in \u001b[0;36msummary\u001b[1;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[0;32m     68\u001b[0m model\u001b[38;5;241m.\u001b[39mapply(register_hook)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# make a forward pass\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# print(x.shape)\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m model(\u001b[38;5;241m*\u001b[39mx)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# remove these hooks\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m hooks:\n",
      "File \u001b[1;32mD:\\Software\\Anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Software\\Anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Chintan\\Workspace\\ERAv2\\S7\\model.py:25\u001b[0m, in \u001b[0;36mNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     23\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(F\u001b[38;5;241m.\u001b[39mmax_pool2d(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv4(x), \u001b[38;5;241m2\u001b[39m)) \u001b[38;5;66;03m# 10>8>4 | 10>14>16 | 2>2>4\u001b[39;00m\n\u001b[0;32m     24\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv5(x), \u001b[38;5;241m2\u001b[39m) \u001b[38;5;66;03m# 4>2 | 10>14>16 | 2>2>4\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv6(x), \u001b[38;5;241m2\u001b[39m) \u001b[38;5;66;03m# 2>1 | 10>14>16 | 2>2>4\u001b[39;00m\n\u001b[0;32m     26\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1024\u001b[39m) \u001b[38;5;66;03m# 1*1*1024 = 1024\u001b[39;00m\n\u001b[0;32m     27\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x))\n",
      "File \u001b[1;32mD:\\Software\\Anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Software\\Anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1568\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1565\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[0;32m   1566\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[1;32m-> 1568\u001b[0m result \u001b[38;5;241m=\u001b[39m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1569\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[0;32m   1570\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[0;32m   1571\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[0;32m   1572\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[0;32m   1573\u001b[0m     ):\n\u001b[0;32m   1574\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Software\\Anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[1;32mD:\\Software\\Anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    457\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Calculated padded input size per channel: (2 x 2). Kernel size: (3 x 3). Kernel size can't be greater than actual input size"
     ]
    }
   ],
   "source": [
    "mymodel = model.Net().to(device)\n",
    "\n",
    "summary(mymodel, input_size=(1, 28, 28))\n",
    "\n",
    "optimizer = optim.SGD(mymodel.parameters(), lr=0.01, momentum=0.9)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1, verbose=True)\n",
    "# New Line\n",
    "criterion = F.nll_loss\n",
    "num_epochs = 15\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "  print(f'Epoch {epoch}')\n",
    "  train_acc, train_loss = utils.train(mymodel, device, train_loader, optimizer, criterion)\n",
    "  test_acc, test_loss = utils.test(mymodel, device, test_loader, criterion)\n",
    "  train_accs.append(train_acc)\n",
    "  train_losses.append(train_loss)\n",
    "  test_accs.append(test_acc)\n",
    "  test_losses.append(test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wBYdhqpx7ML2"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R4AGuMJUsEso"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B-LM-Z1k6FcF"
   },
   "source": [
    "CODE BLOCK: 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SRTtZqmhBXGc"
   },
   "source": [
    "### [8. Model Accuracy and Loss plots visualization](#section-8)\n",
    "- Part of utils\n",
    "- Drawing plots of Training and Testing accuracy and loss\n",
    "- This gives us an understanding of how the accuracy and losses improved over epochs\n",
    "- Also helps to understand where we should have stopped the training for optimum results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "Wu0l7dli4eC9",
    "outputId": "e1fbef8a-2ccd-446e-842d-058b85cf2822"
   },
   "outputs": [],
   "source": [
    "utils.drawLossAccuracyPlots(train_losses, train_accs, test_losses, test_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tiuPNnuoFOOd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
